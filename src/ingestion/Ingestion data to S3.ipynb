{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da75ffd8-bdfa-46e9-b3d5-68b179b5da95",
   "metadata": {},
   "source": [
    "# Data Ingestion into raw folders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919dfcf2-1dda-472d-8b4c-3e7700891442",
   "metadata": {},
   "source": [
    "## support_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e6d00b-2266-4d4b-89d2-4e23de2382ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "LOGS_FOLDER = \"day-wise-logs-data/\"\n",
    "DATE_TRACKER_FILE = \"log_date_tracker.txt\"\n",
    "\n",
    "S3_BUCKET = \"my-careplus-data\" # this should match the exact bucket name you have setup in AWS S2\n",
    "S3_PREFIX = \"support-logs/raw/\"\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.getenv(\"REGION\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54468eae-f1aa-4d93-a030-9b380b7989cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "AWS_CONFIG = {\n",
    "    \"aws_access_key_id\": os.getenv(\"AWS_ACCESS_KEY\"),\n",
    "    \"aws_secret_access_key\": os.getenv(\"SECRET_KEY\"),\n",
    "    \"region_name\": os.getenv(\"REGION\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e32c1f9-c3d6-4e8a-b750-b74275388799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- UTILITY FUNCTIONS ----------\n",
    "def read_last_date(file_path):\n",
    "    if os.path.exists(file_path):\n",
    "        with open(file_path, 'r') as f:\n",
    "            return f.read().strip()\n",
    "    return \"2025-06-30\"\n",
    "\n",
    "def update_last_date(file_path, new_date):\n",
    "    with open(file_path, 'w') as f:\n",
    "        f.write(new_date)\n",
    "\n",
    "def get_next_date(last_date_str):\n",
    "    last_date = datetime.strptime(last_date_str, \"%Y-%m-%d\")\n",
    "    next_date = last_date + timedelta(days=1)\n",
    "    return next_date.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "\n",
    "def upload_log_file_to_s3(file_path, bucket, key):\n",
    "    s3 = boto3.client('s3', **AWS_CONFIG)\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "    s3.put_object(Bucket=bucket, Key=key, Body=content)\n",
    "    print(f\"‚úÖ Uploaded log file to s3://{bucket}/{key}\")\n",
    "\n",
    "\n",
    "# ---------- MAIN INGESTION LOGIC ----------\n",
    "def run_log_ingestion():\n",
    "    last_date = read_last_date(DATE_TRACKER_FILE)\n",
    "    next_date = get_next_date(last_date)\n",
    "    print(last_date, next_date)\n",
    "\n",
    "    file_name = f\"support_logs_{next_date}.log\"\n",
    "    log_file_full_path = os.path.join(LOGS_FOLDER, file_name)\n",
    "    print(log_file_full_path)\n",
    "    \n",
    "\n",
    "    s3_key = f\"{S3_PREFIX}support_logs_{next_date}.log\"\n",
    "    upload_log_file_to_s3(log_file_full_path, S3_BUCKET, s3_key)\n",
    "    update_last_date(DATE_TRACKER_FILE, next_date)\n",
    "    print(f\"üìÖ Updated tracker to {next_date}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14511285-4c44-4e73-bd1b-960b6a86d34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- RUN ----------\n",
    "if __name__ == \"__main__\":\n",
    "    run_log_ingestion()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6524b1-8028-44d3-a53e-a41f83521311",
   "metadata": {},
   "source": [
    "## support_tickets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5708c4-aa26-43c1-b69b-87948a3f8b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import boto3\n",
    "from io import StringIO\n",
    "from sqlalchemy import create_engine\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b9e883-da23-4836-8a2d-29de8c0e819b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- CONFIG ----------\n",
    "db_config = {\n",
    "    \"host\": \"localhost\",\n",
    "    \"port\": \"3306\",\n",
    "    \"user\": \"root\",  # change\n",
    "    \"password\": \"#####\", # change\n",
    "    \"database\": \"careplus_support_db\"\n",
    "}\n",
    "\n",
    "S3_BUCKET = \"my-careplus-data\" \n",
    "S3_PREFIX = \"support-tickets/raw/\"  \n",
    "DATE_TRACKER_FILE = \"date_tracker.txt\"\n",
    "\n",
    "import os\n",
    "\n",
    "AWS_CONFIG = {\n",
    "    \"aws_access_key_id\": os.getenv(\"AWS_ACCESS_KEY\"),\n",
    "    \"aws_secret_access_key\": os.getenv(\"SECRET_KEY\"),\n",
    "    \"region_name\": os.getenv(\"REGION\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5628fa-2c7c-4d98-900d-5a3b0c5392e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- UTILITY FUNCTIONS ----------\n",
    "def get_engine(config):\n",
    "    return create_engine(f\"mysql+pymysql://{config['user']}:{config['password']}@{config['host']}:{config['port']}/{config['database']}\")\n",
    "\n",
    "def upload_to_s3(df, bucket, key):\n",
    "    csv_buffer = StringIO()\n",
    "    df.to_csv(csv_buffer, index=False)\n",
    "\n",
    "    s3 = boto3.client('s3', **AWS_CONFIG)\n",
    "    s3.put_object(Bucket=bucket, Key=key, Body=csv_buffer.getvalue())\n",
    "    print(f\"‚úÖ Uploaded to s3://{bucket}/{key}\")\n",
    "\n",
    "def read_last_date(file_path):\n",
    "    if os.path.exists(file_path):\n",
    "        with open(file_path, 'r') as f:\n",
    "            return f.read().strip()\n",
    "    return \"2025-06-30\"  # Starting point before 1st July\n",
    "\n",
    "def update_last_date(file_path, new_date):\n",
    "    with open(file_path, 'w') as f:\n",
    "        f.write(new_date)\n",
    "\n",
    "def get_next_date(last_date_str):\n",
    "    last_date = datetime.strptime(last_date_str, \"%Y-%m-%d\")\n",
    "    next_date = last_date + timedelta(days=1)\n",
    "    return next_date.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# ---------- MAIN INGESTION LOGIC ----------\n",
    "def run_ingestion():\n",
    "    engine = get_engine(db_config)\n",
    "    last_date = read_last_date(DATE_TRACKER_FILE)\n",
    "    next_date = get_next_date(last_date)\n",
    "\n",
    "    # Query only that day‚Äôs data\n",
    "    query = f\"\"\"\n",
    "        SELECT * FROM support_tickets\n",
    "        WHERE DATE(created_at) = '{next_date}';\n",
    "    \"\"\"\n",
    "    df = pd.read_sql(query, engine)\n",
    "    print(df.shape)\n",
    "    print(df.head())\n",
    "\n",
    "    if df.empty:\n",
    "        print(f\"‚ö†Ô∏è No data found for {next_date}. Skipping upload.\")\n",
    "        return\n",
    "\n",
    "    # Upload to S3\n",
    "    s3_key = f\"{S3_PREFIX}support_tickets_{next_date}.csv\"\n",
    "    upload_to_s3(df, S3_BUCKET, s3_key)\n",
    "\n",
    "    # Update date tracker\n",
    "    update_last_date(DATE_TRACKER_FILE, next_date)\n",
    "    print(f\"üìÖ Updated tracker to {next_date}\")\n",
    "\n",
    "# Run\n",
    "if __name__ == \"__main__\":\n",
    "    run_ingestion()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
